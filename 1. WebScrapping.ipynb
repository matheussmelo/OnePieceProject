{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WebScrapping dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa primeira parte consiste na coleta dos dados, com ferramentas de WebScrapping como Selenium e BeautifulSoup, do site de avaliações [IMDb](https://www.imdb.com/title/tt0388629/episodes/?ref_=tt_eps_sm).\n",
    "\n",
    "As informações são relacionadas às avaliações dos episódios do anime One Piece, que se configura como um dos animes mais populares e com maior quantidade de episódios (ainda contando) da atualidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliotecas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link para cada episódio com Selenium\n",
    "\n",
    "Essa etapa serve para acessar a página principal de avaliações com todos os episódios e pegar o link de cada um para direcionar à uma página com informações exclusivas de cada episódio. \n",
    "\n",
    "Não foi possível obter os dados nessa página principal, por isso foi necessário coletar o link externo para cada episódio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicie o navegador (você precisa ter o driver correspondente, ex: chromedriver)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Acesse a página\n",
    "url = 'https://www.imdb.com/title/tt0388629/episodes/?ref_=tt_eps_sm'\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "# Aguarde alguns segundos para a página carregar\n",
    "time.sleep(3)\n",
    "\n",
    "# Localize e clique no botão \"Mostrar tudo\" (ajuste o seletor conforme necessário)\n",
    "# Aguarde até que o botão seja clicável\n",
    "try:\n",
    "    button1 = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"__next\"]/main/div/section/div/section/div/div[1]/section[2]/section[2]/article[51]/div/span[2]')))\n",
    "\n",
    "    # Rolar até o botão antes de clicar\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", button1)\n",
    "    time.sleep(3)  # Aguarde um segundo para garantir que o botão está visível\n",
    "\n",
    "    button1.click()  # Clica no botão \"Tudo\"\n",
    "\n",
    "    #time.sleep(45)\n",
    "    time.sleep(10)\n",
    "    \n",
    "    episodes = list()\n",
    "\n",
    "    for i in range(1,1118):\n",
    "\n",
    "        try:\n",
    "            episode = driver.find_element(By.XPATH, f'//*[@id=\"__next\"]/main/div/section/div/section/div/div[1]/section[2]/section[2]/article[{i}]/div/div/div[3]/div[1]/h4/div/a').get_attribute('href')\n",
    "            \n",
    "        except:\n",
    "            try:\n",
    "                episode = driver.find_element(By.XPATH, f'//*[@id=\"__next\"]/main/div/section/div/section/div/div[1]/section[2]/section[2]/article[{i}]/div/div/div[3]/div[2]/h4/div/a').get_attribute('href')\n",
    "          \n",
    "            except:\n",
    "                print(f'Algo deu errado com o episódio: {i}')\n",
    "\n",
    "            else:\n",
    "                # Segunda tentativa foi bem-sucedida\n",
    "                print(f'Episódio {i} encontrado: {episode}')\n",
    "        else:\n",
    "            # Primeira tentativa foi bem-sucedida\n",
    "            print(f'Episódio {i} encontrado: {episode}')\n",
    "\n",
    "        episodes.append(episode)            \n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "finally: \n",
    "    # Feche o navegador\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coleta dos dados de cada episódio com Beutiful Soup\n",
    "\n",
    "Essa etapa consistiu em utilizar o BeautifulSoup para obter as informações de cada link entre os 1117 episódios e gerar um DataFrame com todos os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_dict = {\n",
    "    'Episódio': [], # content_data['series']['episodeNumber']['episodeNumber']\n",
    "    'Título': [], #content_data['titleText']['text']\n",
    "    'Lançamento': [],\n",
    "    'Votos': [], #content_data['ratingsSummary']['voteCount']\n",
    "    'Avaliação': []     #content_data['ratingsSummary']['aggregateRating']\n",
    "    }\n",
    "\n",
    "ep_count = 1\n",
    "\n",
    "for episode in episodes:\n",
    "\n",
    "    # Simule o comportamento de um navegador adicionando um cabeçalho 'User-Agent'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    # Faça a requisição usando o cabeçalho\n",
    "    response = requests.get(episode, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')  \n",
    "\n",
    "    script = soup.find('script', id=\"__NEXT_DATA__\", type=\"application/json\")\n",
    "\n",
    "    json_data = script.string\n",
    "                \n",
    "    # Converta a string JSON em um dicionário Python\n",
    "    data = json.loads(json_data)\n",
    "\n",
    "    # Exemplo: Acesse as chaves dentro do dicionário\n",
    "    content_data = data['props']['pageProps']['aboveTheFoldData']\n",
    "\n",
    "    episodes_dict['Episódio'].append(content_data['series']['episodeNumber']['episodeNumber'])\n",
    "    episodes_dict['Título'].append(content_data['titleText']['text'])\n",
    "\n",
    "    dia, mês, ano = content_data['releaseDate']['day'], content_data['releaseDate']['month'], content_data['releaseDate']['year']\n",
    "    episodes_dict['Lançamento'].append(datetime.date(ano, mês, dia))\n",
    "    \n",
    "    episodes_dict['Qtd de votos'].append(content_data['ratingsSummary']['voteCount'])\n",
    "    episodes_dict['Avaliação média'].append(content_data['ratingsSummary']['aggregateRating'])\n",
    "\n",
    "    print(f'Episódio {ep_count} processado.')\n",
    "\n",
    "    ep_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_episodes = pd.DataFrame(episodes_dict)\n",
    "df_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_episodes.to_excel('.../episodes.xlsx', index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
